{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-28T23:47:24.337717Z",
     "start_time": "2025-01-28T23:47:24.333428Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import jax.numpy as jnp\n",
    "import jax\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from utils.oversampling import fit_resample\n",
    "from utils.data_processer import *"
   ],
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-28T23:47:26.210963Z",
     "start_time": "2025-01-28T23:47:25.373453Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data = pd.read_csv(\"../creditcard_2021.csv\")\n",
    "print(f\"Number of samples: {len(data)}\")\n",
    "print(f\"Number of fraudolent transaction: {(data['Class'] == 1).sum()}\")\n",
    "print(f\"Ratio of fraudolent transaction: {data['Class'].mean()}\")"
   ],
   "id": "6e03c2571bf11f0a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 284807\n",
      "Number of fraudolent transaction: 492\n",
      "Ratio of fraudolent transaction: 0.001727485630620034\n"
     ]
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Logistic Regression\n",
    "\n",
    "$$z = \\alpha_0 + \\alpha_1X_1 + \\alpha_2X_2 + ... + \\alpha_nX_n$$\n",
    "\n",
    "$$y_{pred} = sigmoid(q) = \\frac{1}{1 + e^{-q}}$$"
   ],
   "id": "abb0d306a5203aa6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-28T23:47:27.616213Z",
     "start_time": "2025-01-28T23:47:27.598093Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class LogisticRegression:\n",
    "    def __init__(self, num_features=None):\n",
    "        self.num_features = num_features\n",
    "\n",
    "    def initialize_parameters(self, num_features=None):\n",
    "        \"\"\"\n",
    "            Sets the parameters (weights and bias) for the logistic regression given the number of features\n",
    "\n",
    "            Returns the parameters of the logistic regression given the number of\n",
    "            neurons of its layers, namely it sets the vector of weights and the bias, initialized randomly\n",
    "\n",
    "            Parameters:\n",
    "            num_features: integer - number of features of the considered dataset\n",
    "\n",
    "            Returns:\n",
    "            weights: ndarray - vector of weights\n",
    "            bias: float - bias term\n",
    "\n",
    "            Raises:\n",
    "            exception: if num_features are not provided\n",
    "        \"\"\"\n",
    "\n",
    "        self.num_features = num_features\n",
    "\n",
    "        if self.num_features is None:\n",
    "            raise Exception(\"Number of features must be provided\")\n",
    "\n",
    "        np.random.seed(0)  # For reproducibility\n",
    "\n",
    "        # Parameters\n",
    "        weights = np.random.randn(self.num_features, 1)\n",
    "        bias = 0.\n",
    "\n",
    "        return weights, bias\n",
    "\n",
    "    # Loss functions\n",
    "    def cross_entropy(self):\n",
    "        @jax.jit\n",
    "        def callable(x=None, y=None, weights=None, bias=None):\n",
    "            \"\"\"\n",
    "                Computes the Cross Entropy Cost function\n",
    "\n",
    "                Parameters:\n",
    "                x: ndarray - input of the logistic regression\n",
    "                y: ndarray - correct value of the output, one-hot representation\n",
    "                weights: ndarray - vector of weights\n",
    "                bias: float - bias term\n",
    "\n",
    "                Returns:\n",
    "                float - Cross Entropy Cost between the predictions of the logistic regression and the correct values\n",
    "\n",
    "                Raises:\n",
    "                exception: if x is not provided\n",
    "                exception: if y is not provided\n",
    "                exception: if weights and bias are not provided\n",
    "            \"\"\"\n",
    "\n",
    "            if x is None:\n",
    "                raise Exception(\"x is not provided\")\n",
    "            if y is None:\n",
    "                raise Exception(\"y is not provided\")\n",
    "            if weights is None or bias is None:\n",
    "                raise Exception(\"params (weights and/or bias) are not provided\")\n",
    "\n",
    "            y_pred = self.predict(x, weights, bias)\n",
    "            return -jnp.mean(y * jnp.log(y_pred) + (1 - y) * jnp.log(1 - y_pred))\n",
    "        return callable\n",
    "\n",
    "    def mean_squared_error(self):\n",
    "        @jax.jit\n",
    "        def callable(x, y, weights, bias):\n",
    "            \"\"\"\n",
    "                Computes the Mean Squared Error\n",
    "\n",
    "                Parameters:\n",
    "                x: ndarray - input of the regression model\n",
    "                y: ndarray - correct value of the output, one-hot representation\n",
    "                weights: ndarray - vector of weights\n",
    "                bias: float - bias term\n",
    "\n",
    "                Returns:\n",
    "                float - Mean Squared Error between the predictions of the regression model and the correct values\n",
    "\n",
    "                Raises:\n",
    "                exception: if x is not provided\n",
    "                exception: if y is not provided\n",
    "                exception: if weights and bias are not provided\n",
    "            \"\"\"\n",
    "\n",
    "            if x is None:\n",
    "                raise Exception(\"x is not provided\")\n",
    "            if y is None:\n",
    "                raise Exception(\"y is not provided\")\n",
    "            if weights is None or bias is None:\n",
    "                raise Exception(\"params (weights and/or bias) are not provided\")\n",
    "\n",
    "            y_pred = self.predict(x, weights, bias)\n",
    "            return jnp.mean((y_pred - y) ** 2)\n",
    "        return callable\n",
    "\n",
    "    # Metrics\n",
    "    def confusion_matrix(self, true_labels, pred_labels):\n",
    "        \"\"\"\n",
    "            Computes the confusion matrix\n",
    "\n",
    "            Parameters:\n",
    "            true_labels: ndarray - correct values of the samples' class'\n",
    "            pred_labels: ndarray - predicted values of the samples' class'\n",
    "\n",
    "            Returns:\n",
    "            TP: float - true positives - attacks classified accurately as attacks\n",
    "            TN: float - true negatives - normal transactions accurately classified as normal\n",
    "            FP: float - false positives - normal traffic incorrectly classified as attacks\n",
    "            FN: float - false negatives - attacks incorrectly classified as normal\n",
    "        \"\"\"\n",
    "\n",
    "        TP = np.sum(np.logical_and(pred_labels == 1., true_labels == 1.))\n",
    "        TN = np.sum(np.logical_and(pred_labels == 0., true_labels == 0.))\n",
    "        FP = np.sum(np.logical_and(pred_labels == 1., true_labels == 0.))\n",
    "        FN = np.sum(np.logical_and(pred_labels == 0., true_labels == 1.))\n",
    "\n",
    "        return TP, TN, FP, FN\n",
    "\n",
    "    def accuracy(self, true_labels, pred_labels):\n",
    "        \"\"\"\n",
    "            Computes the accuracy of the predictions\n",
    "\n",
    "            Parameters:\n",
    "            true_labels: ndarray - correct values of the samples' class'\n",
    "            pred_labels: ndarray - predicted values of the samples' class'\n",
    "\n",
    "            Returns:\n",
    "            float - accuracy of the artificial neural network, namely the number of samples\n",
    "                    correctly classified divided by the total number of samples\n",
    "        \"\"\"\n",
    "        TP, TN, _, _ = self.confusion_matrix(true_labels, pred_labels)\n",
    "        AC = ((TN + TP) / len(pred_labels)) * 100 # accuracy\n",
    "        return round(float(AC), 2)\n",
    "\n",
    "    def recall(self, true_labels, pred_labels):\n",
    "        \"\"\"\n",
    "            Computes the recall (or sensitivity) of the predictions\n",
    "\n",
    "            Parameters:\n",
    "            true_labels: ndarray - correct values of the samples' class'\n",
    "            pred_labels: ndarray - predicted values of the samples' class'\n",
    "\n",
    "            Returns:\n",
    "            float - recall of the artificial neural network,\n",
    "                    namely the percentage of positive predictions (true positive rate),\n",
    "                    out of the total positive\n",
    "        \"\"\"\n",
    "        TP, _, _, FN = self.confusion_matrix(true_labels, pred_labels)\n",
    "        RC = (TP / (TP + FN)) * 100 # recall\n",
    "        return round(float(RC), 2)\n",
    "\n",
    "    def precision(self, true_labels, pred_labels):\n",
    "        \"\"\"\n",
    "            Computes the precision of the predictions\n",
    "\n",
    "            Parameters:\n",
    "            true_labels: ndarray - correct values of the samples' class'\n",
    "            pred_labels: ndarray - predicted values of the samples' class'\n",
    "\n",
    "            Returns:\n",
    "            float - precision of the artificial neural network, namely the percentage of truly positive,\n",
    "                    out of all positive predicted\n",
    "        \"\"\"\n",
    "        TP, _, FP, _ = self.confusion_matrix(true_labels, pred_labels)\n",
    "        PR = (TP / (TP + FP)) * 100 # precision\n",
    "        return round(float(PR), 2)\n",
    "\n",
    "    def f1_score(self, true_labels, pred_labels):\n",
    "        \"\"\"\n",
    "            Computes the F1 Score of the predictions\n",
    "\n",
    "            Parameters:\n",
    "            true_labels: ndarray - correct values of the samples' class'\n",
    "            pred_labels: ndarray - predicted values of the samples' class'\n",
    "\n",
    "            Returns:\n",
    "            float - f1 score of the artificial neural network, namely the harmonic mean of precision and recall.\n",
    "                    It takes both false positive and false negatives into account\n",
    "        \"\"\"\n",
    "        RC = self.recall(true_labels, pred_labels)\n",
    "        PR = self.precision(true_labels, pred_labels)\n",
    "        F1 = 2 * PR * RC / (PR + RC) # f1 score\n",
    "        return round(float(F1), 2)\n",
    "\n",
    "    def metrics(self, true_labels, pred_labels, metrics_df=None, dataset_label=''):\n",
    "        \"\"\"\n",
    "            Computes and print metrics TP, TN, FP, FN, AC, RC, PC, F1\n",
    "\n",
    "            Parameters:\n",
    "            predictions: ndarray - predictions of samples obtained with a model\n",
    "            true_labels: ndarray - true labels of the samples\n",
    "            metrics_df: DataFrame - DataFrame to which the computed statistics have to be put\n",
    "            dataset_label: str - label identifying the belonging of the statistics to its dataset\n",
    "\n",
    "            Returns:\n",
    "            DataFrame - DataFrame containing the statistics contained in the parameter metrics_df\n",
    "                        plus the statistics computed on the new predictions\n",
    "        \"\"\"\n",
    "\n",
    "        TP, TN, FP, FN = self.confusion_matrix(true_labels, pred_labels)\n",
    "\n",
    "        AC = self.accuracy(true_labels, pred_labels)\n",
    "        RC = self.recall(true_labels, pred_labels)\n",
    "        PR = self.precision(true_labels, pred_labels)\n",
    "        F1 = self.f1_score(true_labels, pred_labels)\n",
    "\n",
    "        if metrics_df is None:\n",
    "            columns = ['Set of features', 'TP', 'TN', 'FP', 'FN', 'accuracy', 'recall', 'precision', 'F1-score']\n",
    "            metrics_df = pd.DataFrame([[dataset_label, TP, TN, FP, FN, AC, RC, PR, F1]], columns=columns)\n",
    "        else:\n",
    "            columns = ['Set of features', 'TP', 'TN', 'FP', 'FN', 'accuracy', 'recall', 'precision', 'F1-score']\n",
    "            metrics_df = pd.concat([metrics_df, pd.DataFrame([[dataset_label, TP, TN, FP, FN, AC, RC, PR, F1]], columns=columns)], ignore_index=True)\n",
    "\n",
    "        return metrics_df\n",
    "\n",
    "    # Optimisation algorithms\n",
    "    def SGD(\n",
    "            self,\n",
    "            loss_function,\n",
    "            epochs=1000,\n",
    "            batch_size=128,\n",
    "            learning_rate_min=1e-3,\n",
    "            learning_rate_max=1e-1,\n",
    "            learning_rate_decay=1000,\n",
    "    ):\n",
    "        \"\"\"\n",
    "           Trains the logistic regression with Stochastic Gradient Descent method using mini-batches and\n",
    "            learning rate decay\n",
    "\n",
    "            Parameters:\n",
    "            loss_function: callable - loss function that it used in order to evaluate the cost\n",
    "                                        between the predictions and the correct values\n",
    "            epochs: int - number of epochs to perform\n",
    "            batch_size: int, optional - size of the batches to be used for computing the gradient\n",
    "            learning_rate_min: float - minimum learning rate used in the training phase\n",
    "            learning_rate_max: float - maximum learning rate used in the training phase\n",
    "            learning_rate_decay: float - learning rate decay used in the training phase\n",
    "\n",
    "            Returns:\n",
    "            weights: ndarray - optimized vector of weights\n",
    "            bias: float - optimized bias term\n",
    "            history: list - history of the loss function optimisation\n",
    "        \"\"\"\n",
    "        def callable(x_train, y_train, weights, bias):\n",
    "            # Number of samples\n",
    "            num_samples = x_train.shape[0]\n",
    "\n",
    "            # Loss and it's gradient functions\n",
    "            loss = jax.jit(loss_function)\n",
    "            grad_loss = jax.jit(jax.grad(loss_function, argnums=[2,3]))\n",
    "\n",
    "            # History\n",
    "            history = list()\n",
    "            history.append(loss(x_train, y_train, weights, bias))\n",
    "\n",
    "            for epoch in range(epochs):\n",
    "                # Get learning rate\n",
    "                learning_rate = max(learning_rate_min, learning_rate_max * (1 - epoch/learning_rate_decay))\n",
    "\n",
    "                # Select batch_size indices randomly\n",
    "                idxs = np.random.choice(num_samples, batch_size)\n",
    "\n",
    "                # Calculate gradient\n",
    "                grad_vals = grad_loss(x_train[idxs,:], y_train[idxs,:], weights, bias)\n",
    "\n",
    "                # Update weights and bias\n",
    "                weights = weights - learning_rate * grad_vals[0]\n",
    "                bias = bias - learning_rate * grad_vals[1]\n",
    "\n",
    "                # Update history\n",
    "                history.append(loss(x_train, y_train, weights, bias))\n",
    "            return weights, bias, history\n",
    "        return callable\n",
    "\n",
    "    def SGD_momentum(\n",
    "            self,\n",
    "            loss_function,\n",
    "            epochs=1000,\n",
    "            batch_size=128,\n",
    "            learning_rate_min=1e-3,\n",
    "            learning_rate_max=1e-1,\n",
    "            learning_rate_decay=1000,\n",
    "            momentum=0.9,\n",
    "    ):\n",
    "        \"\"\"\n",
    "            Trains the logistic regression with Stochastic Gradient Descent method with Momentum\n",
    "            using mini-batches and learning rate decay\n",
    "\n",
    "            Parameters:\n",
    "            loss_function: callable - loss function that it used in order to evaluate the cost\n",
    "                                    between the predictions and the correct values\n",
    "            epochs: int - number of epochs to perform\n",
    "            batch_size: int, optional - size of the batches to be used for computing the gradient\n",
    "            learning_rate_min: float - minimum learning rate used in the training phase\n",
    "            learning_rate_max: float - maximum learning rate used in the training phase\n",
    "            learning_rate_decay: float - learning rate decay used in the training phase\n",
    "            momentum: float - momentum used in the training phase\n",
    "\n",
    "            Returns:\n",
    "            weights: ndarray - optimized vector of weights\n",
    "            bias: float - optimized bias term\n",
    "            history: list - history of the loss function optimisation\n",
    "        \"\"\"\n",
    "        def callable(x_train, y_train, weights, bias):\n",
    "            # Number of samples\n",
    "            num_samples = x_train.shape[0]\n",
    "\n",
    "            # Loss and it's gradient functions\n",
    "            loss = jax.jit(loss_function)\n",
    "            grad_loss = jax.jit(jax.grad(loss_function, argnums=[2, 3]))\n",
    "\n",
    "            # History\n",
    "            history = list()\n",
    "            history.append(loss(x_train, y_train, weights, bias))\n",
    "\n",
    "            # Initialize velocities\n",
    "            weights_velocity = np.zeros_like(weights)\n",
    "            bias_velocity = 0.\n",
    "\n",
    "            for epoch in range(epochs):\n",
    "                # Get learning rate\n",
    "                learning_rate = max(learning_rate_min, learning_rate_max * (1 - epoch/learning_rate_decay))\n",
    "\n",
    "                # Select batch_size indices randomly\n",
    "                idxs = np.random.choice(num_samples, batch_size)\n",
    "\n",
    "                # Calculate gradient\n",
    "                grad_val = grad_loss(x_train[idxs,:], y_train[idxs,:], weights, bias)\n",
    "\n",
    "                # Compute velocities\n",
    "                weights_velocity = momentum * weights_velocity - learning_rate * grad_val[0]\n",
    "                bias_velocity = momentum * bias_velocity - learning_rate * grad_val[1]\n",
    "\n",
    "                # Update weights and bias\n",
    "                weights = weights + weights_velocity\n",
    "                bias = bias + bias_velocity\n",
    "\n",
    "                # Update history\n",
    "                history.append(loss(x_train, y_train, weights, bias))\n",
    "            return weights, bias, history\n",
    "        return callable\n",
    "\n",
    "    def train(self, x_train, y_train, weights, bias, optimizer):\n",
    "        \"\"\"\n",
    "            Trains the logistic regression using one the optimization algorithms\n",
    "\n",
    "            Parameters:\n",
    "            x_train: ndarray - training set of the dataset to fit\n",
    "            y_train: ndarray - training set's sample's labels\n",
    "            weights: ndarray - vector of weights\n",
    "            bias: float - bias term\n",
    "            optimizer: callable - optimization algorithm to be used in the training phase\n",
    "\n",
    "            Returns:\n",
    "            ndarray - updated weights and bias\n",
    "            ndarray - history of the loss function\n",
    "        \"\"\"\n",
    "\n",
    "        return optimizer(x_train, y_train, weights, bias)\n",
    "\n",
    "    def predict(self, x=None, weights=None, bias=None):\n",
    "        \"\"\"\n",
    "            Computes the predicted labels with logistic regression\n",
    "\n",
    "            Parameters:\n",
    "            x: ndarray - input of the logistic regression\n",
    "            weights: ndarray - vector of weights\n",
    "            bias: float - bias term\n",
    "\n",
    "            Returns:\n",
    "            ndarray - predicted values of the logistic regression\n",
    "\n",
    "            Raises:\n",
    "            Exception - if x is not provided\n",
    "            Exception - if params were not initialized\n",
    "        \"\"\"\n",
    "\n",
    "        if x is None:\n",
    "            raise Exception(\"x is not provided\")\n",
    "        if weights is None or bias is None:\n",
    "            raise Exception(\"Params (weights and/or bias) are not provided\")\n",
    "\n",
    "        # Algorithm\n",
    "        z = bias + x @ weights\n",
    "        y_pred = jax.nn.sigmoid(-z)\n",
    "\n",
    "        return y_pred"
   ],
   "id": "72300877ceefe08",
   "outputs": [],
   "execution_count": 34
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Datasets",
   "id": "c8afe9b7d7c070c5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-28T23:47:31.808473Z",
     "start_time": "2025-01-28T23:47:31.753147Z"
    }
   },
   "cell_type": "code",
   "source": [
    "datasets = list()\n",
    "\n",
    "v1 = ['V1', 'V5', 'V7', 'V8', 'V11', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20', 'V21', 'V22', 'V23', 'V24', 'Amount', 'Class']\n",
    "datasets.append(data[v1])\n",
    "\n",
    "v2 = ['V1', 'V6', 'V13', 'V16', 'V17', 'V22', 'V23', 'V28', 'Amount', 'Class']\n",
    "datasets.append(data[v2])\n",
    "\n",
    "v3 = ['V2', 'V11', 'V12', 'V13', 'V15', 'V16', 'V17', 'V18', 'V20', 'V21', 'V24', 'V26', 'Amount', 'Class']\n",
    "datasets.append(data[v3])\n",
    "\n",
    "v4 = ['V2', 'V7', 'V10', 'V13', 'V15', 'V17', 'V19', 'V28', 'Amount', 'Class']\n",
    "datasets.append(data[v4])\n",
    "\n",
    "v5 = ['Time', 'V1', 'V7', 'V8', 'V9', 'V11', 'V12', 'V14', 'V15', 'V22', 'V27', 'V28', 'Amount', 'Class']\n",
    "datasets.append(data[v5])\n",
    "\n",
    "v6 = data.columns\n",
    "datasets.append(data[v6])\n",
    "\n",
    "v7 = ['V2', 'V4', 'V5', 'V6', 'V11', 'V12', 'V13', 'V16', 'V17', 'V18', 'V20', 'V21', 'V22', 'V23', 'V25', 'V26', 'V28', 'Amount', 'Class']\n",
    "datasets.append(data[v7])"
   ],
   "id": "9d15475a99802c17",
   "outputs": [],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-28T23:47:33.631951Z",
     "start_time": "2025-01-28T23:47:33.629221Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Logistic Regression classifier\n",
    "logistic_classifier = LogisticRegression()"
   ],
   "id": "f36cfb7d9e2d2219",
   "outputs": [],
   "execution_count": 36
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Training and evaluation",
   "id": "1e3f726c97d7d153"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-28T23:56:40.071376Z",
     "start_time": "2025-01-28T23:56:40.063706Z"
    }
   },
   "cell_type": "code",
   "source": [
    "metrics_train_df = None\n",
    "metrics_test_df = None"
   ],
   "id": "1c6e4b0fd562c1ad",
   "outputs": [],
   "execution_count": 43
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-29T00:04:12.586915Z",
     "start_time": "2025-01-29T00:04:12.367348Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Get dataset (based on the feature vectors defined before)\n",
    "input = datasets[0].to_numpy()\n",
    "\n",
    "# Data splitting\n",
    "x_train, y_train, _, _, x_test, y_test = data_split(data_input=input, train_size=0.8)\n",
    "\n",
    "# SMOTE: oversampling\n",
    "n_samples = 6000\n",
    "x_minority = x_train[y_train[:, 0] == 1] # minority class samples (attacks)\n",
    "x_train_synthetic = fit_resample(x_minority, n_samples=n_samples) # generate synthetic data for training\n",
    "y_train_synthetic = np.ones((n_samples,1)) # generate other attack labels as well\n",
    "\n",
    "# Add synthetic data to the original one\n",
    "x_train_normalized = np.concatenate((x_train, x_train_synthetic), axis=0)\n",
    "y_train = np.concatenate((y_train, y_train_synthetic), axis=0)\n",
    "\n",
    "# Training set normalisation\n",
    "x_train_normalized, data_train_min, data_train_max = min_max(data=x_train_normalized)\n",
    "\n",
    "# Validation set normalisation\n",
    "# ...\n",
    "\n",
    "# Testing set normalisation\n",
    "x_test_normalized, _, _ = min_max(x_test, data_train_min, data_train_max)\n",
    "\n",
    "x_train_normalized.shape, y_train.shape, x_test_normalized.shape, y_test.shape"
   ],
   "id": "8741bc42bae4a0c1",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((233845, 18), (233845, 1), (56962, 18), (56962, 1))"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 53
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-29T00:04:43.454183Z",
     "start_time": "2025-01-29T00:04:43.451964Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Initialize weights and biases\n",
    "weights, bias = logistic_classifier.initialize_parameters(num_features=x_train_normalized.shape[1])"
   ],
   "id": "214f72dc167cab5c",
   "outputs": [],
   "execution_count": 55
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-29T00:04:51.196154Z",
     "start_time": "2025-01-29T00:04:46.143598Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# Train ann, with gradient descent - mean squared error\n",
    "updated_weights, updated_bias, history = logistic_classifier.train(\n",
    "    x_train = x_train_normalized,\n",
    "    y_train = y_train,\n",
    "    weights = weights,\n",
    "    bias = bias,\n",
    "    optimizer = logistic_classifier.SGD(\n",
    "        loss_function=logistic_classifier.cross_entropy(),\n",
    "        epochs=2000,\n",
    "        batch_size=256,\n",
    "        learning_rate_min=1e-3,\n",
    "        learning_rate_max=1e-1,\n",
    "        learning_rate_decay=1000\n",
    "    )\n",
    ")\n",
    "updated_weights, bias"
   ],
   "id": "ea344026d0fb4ef9",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Array([[ 1.2710423 ],\n",
       "        [-0.05078766],\n",
       "        [ 0.8590186 ],\n",
       "        [ 1.7420273 ],\n",
       "        [ 1.3794972 ],\n",
       "        [-1.2366097 ],\n",
       "        [ 0.86132795],\n",
       "        [-0.35560134],\n",
       "        [-0.19458424],\n",
       "        [ 0.2123025 ],\n",
       "        [-0.05585384],\n",
       "        [ 1.03299   ],\n",
       "        [ 0.3919882 ],\n",
       "        [-0.24475455],\n",
       "        [ 0.12101985],\n",
       "        [-0.04011032],\n",
       "        [ 1.2655078 ],\n",
       "        [-0.20756428]], dtype=float32),\n",
       " 0.0)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 56
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-29T00:04:53.973159Z",
     "start_time": "2025-01-29T00:04:53.813149Z"
    }
   },
   "cell_type": "code",
   "source": "plt.semilogy(history)",
   "id": "ffd500e415976b50",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x3a2a49b80>]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 57
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-29T00:04:57.172895Z",
     "start_time": "2025-01-29T00:04:57.149863Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# Get training predicted labels\n",
    "train_pred_labels = logistic_classifier.predict(x_train_normalized, updated_weights, updated_bias)\n",
    "train_pred_labels = train_pred_labels >= 0.5\n",
    "\n",
    "train_pred_labels.shape"
   ],
   "id": "a5d73bf7d3954010",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(233845, 1)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 58
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-28T23:54:16.629808Z",
     "start_time": "2025-01-28T23:54:11.135957Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/32/cjb5rw_97rjb1kkd58x5p4q80000gn/T/ipykernel_28996/172079211.py:170: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  PR = (TP / (TP + FP)) * 100 # precision\n"
     ]
    }
   ],
   "execution_count": 40,
   "source": [
    "\n",
    "# Get validation predicted labels\n",
    "# ...\n",
    "\n",
    "# Get testing predicted labels\n",
    "test_pred_labels = logistic_classifier.predict(x_test_normalized, updated_weights, updated_bias)\n",
    "test_pred_labels = test_pred_labels >= 0.5\n",
    "\n",
    "# Print metrics\n",
    "metrics_train_df = logistic_classifier.metrics(\n",
    "    true_labels=y_train,\n",
    "    pred_labels=train_pred_labels,\n",
    "    metrics_df=metrics_train_df,\n",
    "    dataset_label='v' + str(i+1) + ' training'\n",
    ")\n",
    "metrics_test_df = logistic_classifier.metrics(\n",
    "    true_labels=y_test,\n",
    "    pred_labels=test_pred_labels,\n",
    "    metrics_df=metrics_test_df,\n",
    "    dataset_label='v' + str(i+1) + ' testing'\n",
    ")\n",
    "\n"
   ],
   "id": "76ce5354a93b000c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-28T23:49:36.127574Z",
     "start_time": "2025-01-28T23:49:02.788618Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/32/cjb5rw_97rjb1kkd58x5p4q80000gn/T/ipykernel_28996/172079211.py:170: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  PR = (TP / (TP + FP)) * 100 # precision\n",
      "/var/folders/32/cjb5rw_97rjb1kkd58x5p4q80000gn/T/ipykernel_28996/172079211.py:170: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  PR = (TP / (TP + FP)) * 100 # precision\n",
      "/var/folders/32/cjb5rw_97rjb1kkd58x5p4q80000gn/T/ipykernel_28996/172079211.py:170: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  PR = (TP / (TP + FP)) * 100 # precision\n",
      "/var/folders/32/cjb5rw_97rjb1kkd58x5p4q80000gn/T/ipykernel_28996/172079211.py:170: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  PR = (TP / (TP + FP)) * 100 # precision\n",
      "/var/folders/32/cjb5rw_97rjb1kkd58x5p4q80000gn/T/ipykernel_28996/172079211.py:170: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  PR = (TP / (TP + FP)) * 100 # precision\n",
      "/var/folders/32/cjb5rw_97rjb1kkd58x5p4q80000gn/T/ipykernel_28996/172079211.py:170: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  PR = (TP / (TP + FP)) * 100 # precision\n",
      "/var/folders/32/cjb5rw_97rjb1kkd58x5p4q80000gn/T/ipykernel_28996/172079211.py:170: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  PR = (TP / (TP + FP)) * 100 # precision\n"
     ]
    }
   ],
   "execution_count": 38,
   "source": [
    "metrics_train_df = None\n",
    "metrics_test_df = None\n",
    "for i, dataset in enumerate(datasets):\n",
    "    # Get dataset (based on the feature vectors defined before)\n",
    "    input = dataset.to_numpy()\n",
    "\n",
    "    # Data splitting\n",
    "    x_train, y_train, _, _, x_test, y_test = data_split(data_input=input, train_size=0.8)\n",
    "\n",
    "    # SMOTE: oversampling\n",
    "    n_samples = 6000\n",
    "    x_minority = x_train[y_train[:, 0] == 1] # minority class samples (attacks)\n",
    "    x_train_synthetic = fit_resample(x_minority, n_samples=n_samples) # generate synthetic data for training\n",
    "    y_train_synthetic = np.ones((n_samples,1)) # generate other attack labels as well\n",
    "\n",
    "    # Add synthetic data to the original one\n",
    "    x_train_normalized = np.concatenate((x_train, x_train_synthetic), axis=0)\n",
    "    y_train = np.concatenate((y_train, y_train_synthetic), axis=0)\n",
    "\n",
    "    # Training set normalisation\n",
    "    x_train_normalized, data_train_min, data_train_max = min_max(data=x_train_normalized)\n",
    "\n",
    "    # Validation set normalisation\n",
    "    # ...\n",
    "\n",
    "    # Testing set normalisation\n",
    "    x_test_normalized, _, _ = min_max(x_test, data_train_min, data_train_max)\n",
    "\n",
    "    # Initialize weights and biases\n",
    "    weights, bias = logistic_classifier.initialize_parameters(num_features=x_train_normalized.shape[1])\n",
    "\n",
    "    # Train ann, with gradient descent - mean squared error\n",
    "    updated_weights, updated_bias, history = logistic_classifier.train(\n",
    "        x_train = x_train_normalized,\n",
    "        y_train = y_train,\n",
    "        weights = weights,\n",
    "        bias = bias,\n",
    "        optimizer = logistic_classifier.SGD(\n",
    "            loss_function=logistic_classifier.cross_entropy(),\n",
    "            epochs=2000,\n",
    "            batch_size=256,\n",
    "            learning_rate_min=1e-3,\n",
    "            learning_rate_max=1e-1,\n",
    "            learning_rate_decay=1000\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Get training predicted labels\n",
    "    train_pred_labels = logistic_classifier.predict(x_train_normalized, updated_weights, updated_bias)\n",
    "    train_pred_labels = train_pred_labels >= 0.5\n",
    "\n",
    "    # Get validation predicted labels\n",
    "    # ...\n",
    "\n",
    "    # Get testing predicted labels\n",
    "    test_pred_labels = logistic_classifier.predict(x_test_normalized, updated_weights, updated_bias)\n",
    "    test_pred_labels = test_pred_labels >= 0.5\n",
    "\n",
    "    # Print metrics\n",
    "    metrics_train_df = logistic_classifier.metrics(\n",
    "        true_labels=y_train,\n",
    "        pred_labels=train_pred_labels,\n",
    "        metrics_df=metrics_train_df,\n",
    "        dataset_label='v' + str(i+1) + ' training'\n",
    "    )\n",
    "    metrics_test_df = logistic_classifier.metrics(\n",
    "        true_labels=y_test,\n",
    "        pred_labels=test_pred_labels,\n",
    "        metrics_df=metrics_test_df,\n",
    "        dataset_label='v' + str(i+1) + ' testing'\n",
    "    )"
   ],
   "id": "dac804096cc879fd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "metrics_train_df",
   "id": "781c519ecfa44fcf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "metrics_test_df",
   "id": "dd57cf8b5d66cfcb",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
